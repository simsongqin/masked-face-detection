{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CASIA-train.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMl1Y2FniCFj8B0zEu/+aFj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/simsongqin/masked-face-detection/blob/main/CASIA_train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r539ZdKRnOpO",
        "outputId": "090794a8-96b0-454f-a2a7-666639325f36"
      },
      "source": [
        "# connect to google colab\n",
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bUwVS7BQGMwR",
        "outputId": "0903b956-9023-4562-82b7-6dc5fa25dc85"
      },
      "source": [
        "!ls /content/drive/My\\ Drive/cosface_train/*.py\n",
        "!cat /content/drive/My\\ Drive/cosface_train/dataset.py\n",
        "!cat /content/drive/My\\ Drive/cosface_train/layer.py\n",
        "!cat /content/drive/My\\ Drive/cosface_train/net.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'/content/drive/My Drive/cosface_train/dataset.py'\n",
            "'/content/drive/My Drive/cosface_train/layer.py'\n",
            "'/content/drive/My Drive/cosface_train/LResnet50.py'\n",
            "'/content/drive/My Drive/cosface_train/net.py'\n",
            "'/content/drive/My Drive/cosface_train/nfold.eval.py'\n",
            "'/content/drive/My Drive/cosface_train/train_old.py'\n",
            "'/content/drive/My Drive/cosface_train/train.py'\n",
            "#!usr/bin/python\n",
            "# -*- coding: utf-8 -*-\n",
            "\n",
            "\n",
            "import torch.utils.data as data\n",
            "from PIL import Image, ImageFile\n",
            "import os\n",
            "# 添加本行，否则出现 IOError: image file is truncated\n",
            "ImageFile.LOAD_TRUNCATED_IAMGES = True\n",
            "\n",
            "'''\n",
            "Desc:\n",
            "    Load Data\n",
            "Date:\n",
            "    2019/05/09\n",
            "Author:\n",
            "    majie1@sensetime.com\n",
            "'''\n",
            "\n",
            "\n",
            "# 加载指定 path 下的数据\n",
            "def PIL_loader(path):\n",
            "    try:\n",
            "        img = Image.open(path).convert('RGB')\n",
            "    except IOError:\n",
            "        print('Cannot load image ' + path)\n",
            "    else:\n",
            "        return img\n",
            "\n",
            "\n",
            "# 加载 fileList 并返回 imgList\n",
            "def default_reader(fileList):\n",
            "    imgList = []\n",
            "    with open(fileList, 'r') as file:\n",
            "        for line in file.readlines():\n",
            "            imgPath, label = line.strip().split(' ')\n",
            "            imgList.append((imgPath, int(label)))\n",
            "    return imgList\n",
            "\n",
            "\n",
            "class ImageList(data.Dataset):\n",
            "    '''\n",
            "    Desc：\n",
            "        重写 ImageList 中的 init ,getitem, len 方法\n",
            "    Args:\n",
            "        root (string): Root directory path.\n",
            "        fileList (string): Image list file path\n",
            "        transform (callable, optional): A function/transform that  takes in an PIL image\n",
            "            and returns a transformed version. E.g, ``transforms.RandomCrop``\n",
            "    '''\n",
            "\n",
            "    def __init__(self, root, fileList, transform=None, list_reader=default_reader, loader=PIL_loader):\n",
            "        self.root = root\n",
            "        self.imgList = list_reader(fileList)\n",
            "        self.transform = transform\n",
            "        self.loader = loader\n",
            "\n",
            "    def __getitem__(self, index):\n",
            "        imgPath, target = self.imgList[index]\n",
            "        img = self.loader(os.path.join(self.root, imgPath))\n",
            "\n",
            "        if self.transform is not None:\n",
            "            img = self.transform(img)\n",
            "        return img, target\n",
            "\n",
            "    def __len__(self):\n",
            "        return len(self.imgList)\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "#!usr/bin/python\n",
            "# -*- coding: utf-8 -*-\n",
            "\n",
            "from __future__ import print_function, division\n",
            "import torch\n",
            "import torch.nn as nn\n",
            "import torch.nn.functional as F\n",
            "from torch.nn import Parameter\n",
            "from torch.autograd import Variable\n",
            "\n",
            "\"\"\"\n",
            "Desc: \n",
            "    compute MarginCosineProduct\n",
            "Date:\n",
            "    2019/05/13\n",
            "Author: \n",
            "    Jesse\n",
            "Contact: \n",
            "    majie1@sensetime.com\n",
            "\n",
            "\"\"\"\n",
            "\n",
            "\n",
            "def cosine_sim(x1, x2, dim=1, eps=1e-8):\n",
            "    ip = torch.mm(x1, x2.t())\n",
            "    w1 = torch.norm(x1, 2, dim)\n",
            "    w2 = torch.norm(x2, 2, dim)\n",
            "    return ip / torch.ger(w1,w2).clamp(min=eps)\n",
            "\n",
            "\n",
            "class MarginCosineProduct(nn.Module):\n",
            "    r\"\"\"large margin cosine distance 的实现 :\n",
            "    Args:\n",
            "        in_features: size of each input sample\n",
            "        out_features: size of each output sample\n",
            "        s: norm of input feature\n",
            "        m: margin\n",
            "    \"\"\"\n",
            "\n",
            "    def __init__(self, in_features, out_features, s=13.10, m=0.40):\n",
            "        super(MarginCosineProduct, self).__init__()\n",
            "        self.in_features = in_features\n",
            "        self.out_features = out_features\n",
            "        self.s = s\n",
            "        self.m = m\n",
            "        self.weight = Parameter(torch.Tensor(out_features, in_features))\n",
            "        nn.init.xavier_uniform_(self.weight)\n",
            "\n",
            "    # forward propagation\n",
            "    def forward(self, input, label):\n",
            "        # --------------------------- cos(theta) & phi(theta) ---------------------------\n",
            "        # cosine = F.linear(F.normalize(input), F.normalize(self.weight))\n",
            "        cosine = cosine_sim(input, self.weight)\n",
            "\n",
            "        one_hot = torch.zeros_like(cosine)\n",
            "        one_hot.scatter_(1, label.view(-1, 1), 1.0)\n",
            "        output = self.s * (cosine - one_hot * self.m)\n",
            "\n",
            "        return output\n",
            "\n",
            "    def __repr__(self):\n",
            "        return self.__class__.__name__ + '(' \\\n",
            "               + 'in_features=' + str(self.in_features) \\\n",
            "               + ', out_features=' + str(self.out_features) \\\n",
            "               + ', s=' + str(self.s) \\\n",
            "               + ', m=' + str(self.m) + ')'\n",
            "#!usr/bin/python\n",
            "# -*- coding: utf-8 -*-\n",
            "\n",
            "import torch\n",
            "import torch.nn as nn\n",
            "\n",
            "\n",
            "class sphere20(nn.Module):\n",
            "    def __init__(self):\n",
            "        super(sphere20, self).__init__()\n",
            "\n",
            "        # input: batch_size, channel_num, pic_width, pic_height (B, 3, 112, 112)\n",
            "\n",
            "        self.conv1_1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=3, stride=2, padding=1)  # => b*64*56*56\n",
            "        self.relu1_1 = nn.ReLU(64)\n",
            "        self.conv1_2 = nn.Conv2d(64, 64, 3, 1, 1, bias=False)  # => b*64*56*56\n",
            "        self.relu1_2 = nn.ReLU(64)\n",
            "        self.conv1_3 = nn.Conv2d(64, 64, 3, 1, 1, bias=False)   # => b*64*56*56\n",
            "        self.relu1_3 = nn.ReLU(64)\n",
            "\n",
            "        self.conv2_1 = nn.Conv2d(64, 128, 3, 2, 1)  # => b*128*28*28\n",
            "        self.relu2_1 = nn.ReLU(128)\n",
            "        self.conv2_2 = nn.Conv2d(128, 128, 3, 1, 1, bias=False)\n",
            "        self.relu2_2 = nn.ReLU(128)\n",
            "        self.conv2_3 = nn.Conv2d(128, 128, 3, 1, 1, bias=False)\n",
            "        self.relu2_3 = nn.ReLU(128)\n",
            "\n",
            "        self.conv3_1 = nn.Conv2d(128, 256, 3, 2, 1)  # => b*256*14*14\n",
            "        self.relu3_1 = nn.ReLU(256)\n",
            "        self.conv3_2 = nn.Conv2d(256, 256, 3, 1, 1, bias=False)\n",
            "        self.relu3_2 = nn.ReLU(256)\n",
            "        self.conv3_3 = nn.Conv2d(256, 256, 3, 1, 1, bias=False)\n",
            "        self.relu3_3 = nn.ReLU(256)\n",
            "\n",
            "        self.conv4_1 = nn.Conv2d(256, 512, 3, 2, 1)  # => b*512*7*7\n",
            "        self.relu4_1 = nn.ReLU(512)\n",
            "        self.conv4_2 = nn.Conv2d(512, 512, 3, 1, 1, bias=False)\n",
            "        self.relu4_2 = nn.ReLU(512)\n",
            "        self.conv4_3 = nn.Conv2d(512, 512, 3, 1, 1, bias=False)\n",
            "        self.relu4_3 = nn.ReLU(512)\n",
            "\n",
            "        self.fc4 = nn.Linear(512 * 7 * 7, 512)\n",
            "\n",
            "        # weight: initialization\n",
            "        for m in self.modules():\n",
            "            # 如果是 卷积层 或者 Linear 层\n",
            "            if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
            "                if m.bias is not None:\n",
            "                    nn.init.kaiming_uniform_(m.weight, nonlinearity='relu')\n",
            "                    nn.init.constant_(m.bias, 0.0)\n",
            "                else:\n",
            "                    nn.init.kaiming_normal_(m.weight, nonlinearity='relu')\n",
            "\n",
            "    def forward(self, x):\n",
            "        x = self.relu1_1(self.conv1_1(x))\n",
            "        x = x + self.relu1_3(self.conv1_3(self.relu1_2(self.conv1_2(x))))\n",
            "\n",
            "        x = self.relu2_1(self.conv2_1(x))\n",
            "        x = x + self.relu2_3(self.conv2_3(self.relu2_2(self.conv2_2(x))))\n",
            "\n",
            "        x = self.relu3_1(self.conv3_1(x))\n",
            "        x = x + self.relu3_3(self.conv3_3(self.relu3_2(self.conv3_2(x))))\n",
            "\n",
            "        x = self.relu4_1(self.conv4_1(x))\n",
            "        x = x + self.relu4_3(self.conv4_3(self.relu4_2(self.conv4_2(x))))\n",
            "\n",
            "        x = x.view(x.size(0), -1)\n",
            "        x = self.fc4(x)\n",
            "\n",
            "        return x\n",
            "\n",
            "    def save(self, file_path):\n",
            "        with open(file_path, 'wb') as f:\n",
            "            torch.save(self.state_dict(), f)\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e_Oux-Rtkm99",
        "outputId": "947fcd98-ad1a-485e-887c-186cea7abe2e"
      },
      "source": [
        "! nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VCfS2NZqniWb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        },
        "outputId": "27135762-d4a9-41be-ea2f-5df2c11ae8fe"
      },
      "source": [
        "#!usr/bin/python\n",
        "# -*- coding: utf-8 -*-\n",
        "\n",
        "from __future__ import print_function, division\n",
        "import os\n",
        "import argparse\n",
        "import time\n",
        "import  pdb\n",
        "import math\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = '0,1,2,3,4,5,6,7'\n",
        "\n",
        "# torch 包\n",
        "import torch\n",
        "import torch.utils.data\n",
        "import torch.optim\n",
        "from torch.autograd import Variable\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import torch.backends.cudnn as cudnn\n",
        "cudnn.benchmarks = True\n",
        "\n",
        "import sys\n",
        "sys.path.append('/content/drive/My Drive/cosface_train')\n",
        "\n",
        "from dataset import ImageList\n",
        "from net import sphere20\n",
        "from layer import MarginCosineProduct\n",
        "import LResnet50\n",
        "\n",
        "DATASET_ROOT = '/content/drive/My Drive/cosface_train/Casia-Webface/'\n",
        "\n",
        "\"\"\"\n",
        "Desc:\n",
        "    complete the training process\n",
        "Dataset:\n",
        "    CASIA-Webface 112 * 96\n",
        "Date:\n",
        "    2019/05/09\n",
        "Author:\n",
        "    Jesse\n",
        "Contact:\n",
        "    majie1@sensetime.com\n",
        "\"\"\"\n",
        "\n",
        "# training parameter\n",
        "parser = argparse.ArgumentParser('Pure implementation of CosFace by Pytorch')\n",
        "parser.add_argument('--root-path', type=str, default= DATASET_ROOT , help='the training set root path')\n",
        "parser.add_argument('--image-list', type=str, default='/content/drive/My Drive/cosface_train/Casia_Webface_112x112_train_list.txt', help='the file and its path of image list')\n",
        "parser.add_argument('--batch-size', type=int, default=128)\n",
        "parser.add_argument('--num-class', type=int, default=10575, help='number of people(class)')\n",
        "parser.add_argument('--epochs', type=int, default=50)\n",
        "parser.add_argument('--lr', type=float, default=0.1)\n",
        "parser.add_argument('--momentum', type=float, default=0.9)\n",
        "parser.add_argument('--weight-decay', type=float, default=5e-4)\n",
        "parser.add_argument('--log-interval', type=float, default=20)\n",
        "#parser.add_argument('--step-size', type=int, default=[16000, 24000])\n",
        "parser.add_argument('--step-size', type=int, default=[55000, 70775, 99085])\n",
        "parser.add_argument('--save-path', type=str, default='/content/drive/My Drive/cosface_train/checkpoints/')\n",
        "parser.add_argument('--no-cuda', type=bool, default=False)\n",
        "parser.add_argument('--workers', type=int, default=4)\n",
        "parser.add_argument('--gpus', type=str, default='0,1,2,3,4,5,6,7')\n",
        "parser.add_argument('--resume', type=bool, default=False)\n",
        "#args = parser.parse_args()\n",
        "args, unknown = parser.parse_known_args()\n",
        "#args.cuda = not args.no_cuda and torch.cuda.is_available()\n",
        "args.cuda = True\n",
        "args.num_class = len(os.listdir(args.root_path))\n",
        "\n",
        "#args = parser.parse_args()\n",
        "#parser.add_argument('-f')\n",
        "\n",
        "def train(train_loader, model, MCP, criterion, optimizer, epoch):\n",
        "    # train\n",
        "    model.train()  # update all params\n",
        "    print_with_time(' Epoch {} start training'.format(epoch))\n",
        "    # get current time\n",
        "    time_curr = time.time()\n",
        "    # show loss\n",
        "    loss_display = 0.0\n",
        "\n",
        "    for batch_idx, (data, target) in enumerate(train_loader, 1):\n",
        "        # iteration number\n",
        "        iteration = (epoch - 1) * len(train_loader) + batch_idx\n",
        "        # adjust lr\n",
        "        adjust_learning_rate(optimizer, iteration, args.step_size)\n",
        "        # use cuda or not\n",
        "        if args.cuda:\n",
        "            data, target = data.cuda(), target.cuda()\n",
        "        data, target = Variable(data), Variable(target)\n",
        "        # compute output\n",
        "        output = model(data)\n",
        "        # pdb.set_trace()\n",
        "        output = MCP(output, target).requires_grad_()   # allomem for gradients\n",
        "\n",
        "        # print('------------------')\n",
        "        # print('output of MCP = ', output.shape)\n",
        "        # print('target = ', target.shape)\n",
        "        # print('---------------------------')\n",
        "        loss = criterion(output, target)\n",
        "\n",
        "        loss_display += loss.detach().item()\n",
        "        # compute gradient and do SGD step\n",
        "        optimizer.zero_grad()\n",
        "        # back propagation\n",
        "        # try:\n",
        "        #     print('loss = ', loss)\n",
        "        # except RuntimeError:\n",
        "        #     pdb.set_trace()\n",
        "        #     print('loss = ', loss)\n",
        "        loss.backward()\n",
        "        # update parameter\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch_idx % args.log_interval == 0:\n",
        "            time_used = time.time() - time_curr\n",
        "            loss_display /= args.log_interval\n",
        "            INFO = ' Margin: {:.4f}, Scale: {:.2f}'.format(MCP.m, MCP.s)\n",
        "            # INFO = ' lambda: {:.4f}'.format(MCP.lamb)\n",
        "            print_with_time(\n",
        "                ' Train Epoch: {} [{}/{} ({:.0f}%)]{}, Loss: {:.6f}, Elapsed time: {:.4f}s({} iters)'.format(\n",
        "                    epoch, batch_idx * len(data), len(train_loader.dataset), 100. * batch_idx / len(train_loader),\n",
        "                    iteration, loss_display, time_used, args.log_interval) + INFO\n",
        "            )\n",
        "            time_curr = time.time()\n",
        "            loss_display = 0.0\n",
        "\n",
        "\n",
        "def print_with_time(string):\n",
        "    print(time.strftime('%Y-%M-%d %H:%M:%S', time.localtime()) + string)\n",
        "\n",
        "\n",
        "def main():\n",
        "    resume = True\n",
        "    if torch.cuda.device_count() > 1:\n",
        "        print('available gpus is ', torch.cuda.device_count(), torch.cuda.get_device_name())\n",
        "    else:\n",
        "        print(\"only one GPU found !!!\")\n",
        "    #model = sphere20()\n",
        "    model = LResnet50.LResNet50E_IR(is_gray = False)\n",
        "    #print (model)\n",
        "    model = torch.nn.DataParallel(model, device_ids = [0],output_device=0).cuda()   # enable mutiple-gpu training\n",
        "\n",
        "    # print(model)\n",
        "\n",
        "    if not os.path.exists(args.save_path):\n",
        "        os.makedirs(args.save_path)\n",
        "    # model.save(args.save_path + '/CosFace_0_checkpoint.pth')\n",
        "\n",
        "    print('save checkpoint finished!')\n",
        "\n",
        "    # upload training dataset\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        ImageList(\n",
        "            root=args.root_path,\n",
        "            fileList=args.image_list,\n",
        "\n",
        "            # processing images\n",
        "            transform=transforms.Compose([\n",
        "                # hflip PIL 图像 at 0.5 probability\n",
        "                transforms.RandomHorizontalFlip(),\n",
        "                # transform a PIL image（H*W*C）in [0, 255] to torch.Tensor(H*W*C) in [0.0, 0.1]\n",
        "                transforms.ToTensor(),  # range [0, 255] -> [0.0, 1.0]\n",
        "                # use mean and standard deviation to normalize data\n",
        "                transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))  # range [0.0, 0.1] -> [-1.0, 1.0]\n",
        "            ])\n",
        "        ),\n",
        "        batch_size=args.batch_size,\n",
        "        shuffle=True,\n",
        "        num_workers=args.workers,\n",
        "        pin_memory=False,\n",
        "        drop_last=True\n",
        "    )\n",
        "\n",
        "    # print the length of train dataset\n",
        "    print('length of train dataset: {}'.format(str(len(train_loader.dataset))))\n",
        "    # print the class number of train dataset\n",
        "    print('Number of Classes: {}'.format(str(args.num_class)))\n",
        "\n",
        "    # --------------------------------loss function and optimizer-------------------------------\n",
        "    # core implementation of Cos face, using cuda\n",
        "    scale = math.sqrt(2) * math.log(args.num_class - 1)\n",
        "    MCP = MarginCosineProduct(512, args.num_class, s=scale).cuda()\n",
        "\n",
        "    criterion = torch.nn.CrossEntropyLoss().cuda()\n",
        "\n",
        "    optimizer = torch.optim.SGD([\n",
        "        {'params': model.parameters()}, {'params': MCP.parameters()}],\n",
        "        lr=args.lr,\n",
        "        momentum=args.momentum,\n",
        "        weight_decay=args.weight_decay\n",
        "    )\n",
        "    if resume:\n",
        "        print (\"resume from epoch 5!\")\n",
        "        pretrained_cnn = torch.load('/content/drive/My Drive/cosface_train/checkpoints/CosFace_4_checkpoint.pth')\n",
        "        pretrained_mcp = torch.load('/content/drive/My Drive/cosface_train/checkpoints/MCP_4_checkpoint.pth') \n",
        "        model.load_state_dict(pretrained_cnn)\n",
        "        MCP.load_state_dict(pretrained_mcp)\n",
        "\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    for epoch in range(5, args.epochs + 1):\n",
        "        train(train_loader, model, MCP, criterion, optimizer, epoch)\n",
        "        #if (epoch % 5 == 0):\n",
        "        torch.save(model.state_dict(), os.path.join(args.save_path, 'CosFace_' + str(epoch) + '_checkpoint.pth'))\n",
        "        torch.save(MCP.state_dict(), os.path.join(args.save_path, 'MCP_' + str(epoch) + '_checkpoint.pth'))\n",
        "\n",
        "    print('Finished Training')\n",
        "\n",
        "\n",
        "# function of adjusting lr\n",
        "def adjust_learning_rate(optimizer, iteration, step_size):\n",
        "    \"\"\"\n",
        "    set lr to the initial LR decayed by 10% for each step size\n",
        "    :param optimizer:\n",
        "    :param iteration:\n",
        "    :param step_size:\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    if iteration in step_size:\n",
        "        lr = args.lr * (0.1 ** (step_size.index(iteration) + 1))\n",
        "        print_with_time('Adjust learning rate to {}'.format(lr))\n",
        "\n",
        "        #  managing parameters using param_groups in optimizer， param_group\n",
        "        #  which including parameter group, corresponding lr, momentum etc.\n",
        "        for param_group in optimizer.param_groups:\n",
        "            param_group['lr'] = lr\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "only one GPU found !!!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-126aa139b337>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-4-126aa139b337>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLResnet50\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLResNet50E_IR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_gray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m     \u001b[0;31m#print (model)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataParallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutput_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# enable mutiple-gpu training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m     \u001b[0;31m# print(model)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mcuda\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    461\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m         \"\"\"\n\u001b[0;32m--> 463\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    357\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    357\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 359\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    379\u001b[0m                 \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m                     \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    382\u001b[0m                 \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    461\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m         \"\"\"\n\u001b[0;32m--> 463\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    170\u001b[0m         \u001b[0;31m# This function throws if there's a driver initialization error, no GPUs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0;31m# are found or any other error occurs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m         \u001b[0;31m# Some of the queued calls may reentrantly call _lazy_init();\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;31m# we need to just return without initializing in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: No CUDA GPUs are available"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zCsX0aeyaq9l"
      },
      "source": [
        "while True:pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "69493JqxF1aT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9SbHvvmHGjKy"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}